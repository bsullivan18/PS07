---
title: "STAT/MATH 495: Problem Set 07"
author: "Brenna Sullivan"
date: "2017-10-24"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(broom)
library(knitr)
library(mosaic)

train <- read_csv("data/cs-training.csv") %>% 
  rename(Id = X1)
test <- read_csv("data/cs-test.csv") %>% 
  rename(Id = X1)
submission <- read_csv("data/sampleEntry.csv")
```

Information on the competition can be found [here](https://www.kaggle.com/c/GiveMeSomeCredit/data).



# Collaboration

Please indicate who you collaborated with on this assignment: 



# Build binary classifier

Build the binary classifier based on a single predictor variable: `DebtRatio`,
`age`, or `MonthlyIncome`. Justify this choice.

```{r}
model_formula <- as.formula(SeriousDlqin2yrs~age)
model_logistic <- glm(model_formula, data=train, family="binomial")

model_logistic %>% 
  broom::tidy(conf.int=TRUE)

model_logistic %>% 
  broom::glance()

log_odds_hat <- predict(model_logistic, newdata=test)
p_hat <- 1/(1 + exp(-log_odds_hat))


predictions <- model_logistic %>% 
  broom::augment(newdata=test) %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted)))

train_augmented <- model_logistic %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1+exp(-.fitted)))
```

```{r}
submission$Id <- test$Id
submission$Probability <- predictions$p_hat

write_csv(submission, "submission.csv")
```


I chose to use `age` as the predictor variable in my model because after compaing plots of all three variables, `age` seemed to give the best indication of whether or not a person has experienced 90 days past due delinquency or worse in the last 2 years.  Also, after comparing the three varibales in terms of AUC, `age` gave the highest.

# ROC curve

Based on the ultimate classifier you choose, plot a corresponding ROC curve.

```{r}
library(ROCR)

pred <- prediction(predictions = train_augmented$p_hat, labels = train_augmented$SeriousDlqin2yrs)
perf <- performance(pred, "tpr","fpr")

auc <- as.numeric(performance(pred,"auc")@y.values)
auc

plot(perf, main=paste("Area Under the Curve =", round(auc, 3)))
abline(c(0, 1), lty=2)
```


# ROC curve for random guessing

Instead of using any predictor information as you did above, switch your
predictions to random guesses and plot the resulting ROC curve.

```{r}
model_formula <- as.formula(SeriousDlqin2yrs~age)
model_logistic <- glm(model_formula, data=train, family="binomial")

model_logistic %>% 
  broom::tidy(conf.int=TRUE)

model_logistic %>% 
  broom::glance()

log_odds_hat <- predict(model_logistic, newdata=test)
p_hat <- 1/(1 + exp(-log_odds_hat))


predictions <- model_logistic %>% 
  broom::augment(newdata=test) %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted)))

train_augmented <- model_logistic %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = .50)
```


```{r}
pred <- prediction(predictions = train_augmented$p_hat, labels = train_augmented$SeriousDlqin2yrs)
perf <- performance(pred, "tpr","fpr")

auc <- as.numeric(performance(pred,"auc")@y.values)
auc

plot(perf, main=paste("Area Under the Curve =", round(auc, 3)))
abline(c(0, 1), lty=2)
```

Here, the ROC curve is the straight line y=x and the AUC is 0.5.
